{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning (Supervised Learning) with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recap of workshop #1 (Pandas)\n",
    "\n",
    "... we will be using pandas again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals of this workshop\n",
    "\n",
    "* What is machine learning and supervised learning?\n",
    "* Become familiar with the scikit learn API\n",
    "* Become familiar with a common flow of how to approach a supervised learning problem\n",
    "* Create your own model to predict values of homes in boston (regression)\n",
    "* Create your own model to classify spam emails (binary classifcation)\n",
    "* Create your own model to classify images of handwritten digits (multi-class classification)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1)\n",
    "### What is Machine Learning?\n",
    "\n",
    "Machine learning is the process of extracting patterns and insight from data automatically. Machine learning models \"learn\" from data that it gets to see and can make inferences or predictions on new, unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning (Regression and Classification)\n",
    "\n",
    "Machine learning can be broadly classified into two categories: **Unsupervised Learning** and **Supervised Learning**\n",
    "\n",
    "In supervised learning, we have data that has both input features and a *desired output*. The task is to build a model to make predictions on unseen data. The data that the model learns from must have labels for the attribute we are trying to predict.\n",
    "\n",
    "Supervised learning is further broken down into two categories: **Classification** and **Regression**\n",
    "\n",
    "In classification, the labels are *discrete*. This means there is a clear distinction between categories. In our email spam task coming up, the labels are \"spam\" or \"not spam\", two distinct categories. In digit classification, the labels are {0,1,...,9}, which make up 10 distinct categories. These categories must be \n",
    "\n",
    "In regression, the labels are continuous. This could be a price of a home, a grade in a course, or the price of a stock. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Representation\n",
    "\n",
    "Before we do any modeling, we have to understand how our data should be organized.\n",
    "\n",
    "Data in scikit-learn is expected to be stored in a 2D array. Think matrices. In this workshop we will refer to this 2D array as **X**.\n",
    "The shape of these arrays is **num_samples** x **num_features**\n",
    "\n",
    "$$\\mathbf{X} = \\begin{bmatrix}\n",
    "    x_{1}^{(1)} & x_{2}^{(1)} & x_{3}^{(1)} & \\dots  & x_{m}^{(1)} \\\\\n",
    "    x_{1}^{(2)} & x_{2}^{(2)} & x_{3}^{(2)} & \\dots  & x_{m}^{(2)} \\\\\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    x_{1}^{(n)} & x_{2}^{(n)} & x_{3}^{(n)} & \\dots  & x_{m}^{(n)}\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "\n",
    "where \n",
    "\n",
    "**num_samples** is the number of observations your dataset contains\n",
    "\n",
    "**num_features** is the number of features or attributes that each one of your observations has. Features can be real-valued or discrete-valued\n",
    "\n",
    "\n",
    "\n",
    "We will refer to the labels as the **y** array\n",
    "\n",
    "$$\\mathbf{y} = \\begin{bmatrix}\n",
    "    y^{(1)} \\\\\n",
    "    y^{(2)}  \\\\\n",
    "    \\vdots \\\\\n",
    "    y^{(n)} \n",
    "\\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # for dataframes, loading data\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "\n",
    "import numpy as np # arrays and matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing data\n",
    "\n",
    "In supervised learning, we use training and testing sets in the process of building a model. Given our available data, we split the data into two sets: the training set and testing set. (70% training and 30% testing is common, but this choice is arbitrary). \n",
    "\n",
    "We will use the training set to train our models and the testing set to test our models. The reason we have to do this is because we cannot both train and test on the same data. Our model's accuracy will be over optimistic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2)\n",
    "# Classification\n",
    "\n",
    "In this section we will work on two classification tasks:\n",
    "\n",
    "1) Classifying images of handwritten digits\n",
    "\n",
    "2) Classifying emails as spam or not spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1)\n",
    "### MNIST handwritten digits\n",
    "\n",
    "This MNIST handwritten digits dataset we will use is a set of 28x28 pixel resolution images of handwritten digits. This is a total of 748 pixels per image and each pixel is a feature. So for this data, each observation has 784 features. Each pixel has a value in [0,255], which represents the shade intensity of the pixel. Most of the pixels have a value of 0, because most of the image is whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv('mnist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 42000 observations and 785 features. One of these columns is actually just the labels. Lets remove that to create the **y** vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data in to **X** matrix and **y** vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mnist = mnist['label']\n",
    "X_mnist = mnist.drop('label', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'The X matrix has %d observations(rows) and %d features(columns)' % (X_mnist.shape[0], X_mnist.shape[1])\n",
    "print 'The y vector has %d rows' % (y_mnist.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the some observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(row_number):\n",
    "    image = np.array(X_mnist.iloc[row_number,:]).reshape(28,28)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_number(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split our data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print X_mnist_train.shape\n",
    "print X_mnist_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest-Neighbours Model\n",
    "\n",
    "http://colah.github.io/posts/2014-10-Visualizing-MNIST/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .predict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .score()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2)\n",
    "# Spam messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spam_header = pd.read_csv('spambase_names.csv')\n",
    "spam = pd.read_csv('spambase.csv', names=list(spam_header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print spam.shape\n",
    "spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize our data into X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_spam = spam['spam']\n",
    "X_spam = spam.drop(['spam'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model\n",
    "\n",
    "Logistic regression is a binary classifier. It models the probability of the True class as:\n",
    "\n",
    "$$ log(\\frac{P(X)}{1-P(X)}) = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2} + ... + \\beta_{m}x_{m} $$\n",
    "\n",
    "where $ x_{1},...,x_{m} $ are the $m$ distinct features and $ \\beta_{0},...,\\beta_{m} $ are the coefficients of the model\n",
    "\n",
    "In the *spam* indicator in our data, 1 means spam and 0 means not spam.\n",
    "\n",
    "$$ log(\\frac{P(Y=1)}{P(Y=0)}) = log(\\frac{P(spam)}{P(not\\_spam)}) = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2} + ... + \\beta_{m}x_{m} $$\n",
    "\n",
    "Basically this models the probability of an email being spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficient Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs = zip(list(X_spam_train),logreg.coef_.tolist()[0])\n",
    "sorted_coefs = sorted(coefs, key = lambda tup: tup[1], reverse=True)\n",
    "sorted_coefs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalaute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .score()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)\n",
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print boston.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boston = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "y_boston = boston.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boston_train, X_boston_test, y_boston_train, y_boston_test = train_test_split(X_boston, y_boston,\n",
    "                                                                               test_size=0.3,\n",
    "                                                                               random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression model\n",
    "\n",
    "The linear regression model is of the form:\n",
    "\n",
    "$$ y = \\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2} + ... + \\beta_{m}x_{m} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init and .fit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_coefs = zip(list(X_boston_train), linreg.coef_.tolist())\n",
    "boston_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(boston_coefs, key = lambda tup: tup[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap of scikit-learn API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist.shape\n",
    "\n",
    "mnist_small = mnist.sample(10000)\n",
    "mnist_small.shape\n",
    "\n",
    "y_mnist_small = mnist_small['label']\n",
    "X_mnist_small = mnist_small.drop('label', axis=1)\n",
    "\n",
    "print X_mnist_small.shape\n",
    "print y_mnist_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = StratifiedKFold(5)\n",
    "\n",
    "scores = cross_val_score(knn, X_mnist_small, y_mnist_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
